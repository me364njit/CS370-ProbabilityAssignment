{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video downloaded to Drone_Tracking_1.mp4\n"
     ]
    }
   ],
   "source": [
    "from pytube import YouTube\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import ssl\n",
    "\n",
    "class YouTubeDownloader:\n",
    "    def __init__(self, video_url):\n",
    "        self.video_url = video_url\n",
    "\n",
    "    def download_video(self, output_path):\n",
    "        try:\n",
    "            # Disable SSL verification\n",
    "            ssl._create_default_https_context = ssl._create_unverified_context\n",
    "            yt = YouTube(self.video_url)\n",
    "            stream = yt.streams.get_highest_resolution()\n",
    "            stream.download(output_path)\n",
    "            print(f\"Video downloaded to {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading video: {e}\")\n",
    "\n",
    "    def download_captions(self, output_path):\n",
    "        try:\n",
    "            # Disable SSL verification\n",
    "            ssl._create_default_https_context = ssl._create_unverified_context\n",
    "            srt = YouTubeTranscriptApi.get_transcript(self.video_url)\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                for caption in srt:\n",
    "                    f.write(\"{}\\n\".format(caption['text']))\n",
    "            print(f\"Captions downloaded to {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading captions: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_url = \"https://www.youtube.com/watch?v=DhmZ6W1UAv4\"\n",
    "   # video_url2 = \"ikh3ncJZPTU\"\n",
    "    output_video_path = \"Drone_Tracking_1.mp4\"\n",
    "   # output_captions_path = \"FiveEyes_captions1.srt\"\n",
    "\n",
    "    downloader = YouTubeDownloader(video_url)\n",
    "   # downloader2 = YouTubeDownloader(video_url2)\n",
    "    downloader.download_video(output_video_path)\n",
    "   # downloader2.download_captions(output_captions_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video downloaded to Drone_Tracking_2.mp4\n"
     ]
    }
   ],
   "source": [
    "from pytube import YouTube\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import ssl\n",
    "\n",
    "class YouTubeDownloader:\n",
    "    def __init__(self, video_url):\n",
    "        self.video_url = video_url\n",
    "\n",
    "    def download_video(self, output_path):\n",
    "        try:\n",
    "            # Disable SSL verification\n",
    "            ssl._create_default_https_context = ssl._create_unverified_context\n",
    "            yt = YouTube(self.video_url)\n",
    "            stream = yt.streams.get_highest_resolution()\n",
    "            stream.download(output_path)\n",
    "            print(f\"Video downloaded to {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading video: {e}\")\n",
    "\n",
    "    def download_captions(self, output_path):\n",
    "        try:\n",
    "            # Disable SSL verification\n",
    "            ssl._create_default_https_context = ssl._create_unverified_context\n",
    "            srt = YouTubeTranscriptApi.get_transcript(self.video_url)\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                for caption in srt:\n",
    "                    f.write(\"{}\\n\".format(caption['text']))\n",
    "            print(f\"Captions downloaded to {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading captions: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_url = \"https://www.youtube.com/watch?v=YrydHPwRelI\"\n",
    "   # video_url2 = \"ikh3ncJZPTU\"\n",
    "    output_video_path = \"Drone_Tracking_2.mp4\"\n",
    "   # output_captions_path = \"FiveEyes_captions1.srt\"\n",
    "\n",
    "    downloader = YouTubeDownloader(video_url)\n",
    "   # downloader2 = YouTubeDownloader(video_url2)\n",
    "    downloader.download_video(output_video_path)\n",
    "   # downloader2.download_captions(output_captions_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Obtaining dependency information for opencv-python from https://files.pythonhosted.org/packages/05/58/7ee92b21cb98689cbe28c69e3cf8ee51f261bfb6bc904ae578736d22d2e7/opencv_python-4.8.1.78-cp37-abi3-macosx_10_16_x86_64.whl.metadata\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-macosx_10_16_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.25.2)\n",
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (4.24.4)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
      "Downloading opencv_python-4.8.1.78-cp37-abi3-macosx_10_16_x86_64.whl (54.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.8.1.78\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python numpy tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/c8/r5_15f0d253fhwl3qpwdr7rm0000gn/T/ipykernel_25981/1921291.py\", line 80, in <module>\n",
      "    detect_drones(video_path, output_folder, yolo_weights_file, yolo_config_file, yolo_classes_file)\n",
      "  File \"/var/folders/c8/r5_15f0d253fhwl3qpwdr7rm0000gn/T/ipykernel_25981/1921291.py\", line -1, in detect_drones\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 1428, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 1319, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 1172, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 1087, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 969, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/Users/muhabelgamal/Library/Python/3.11/lib/python/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def detect_drones(video_path, output_folder, yolo_weights, yolo_config, yolo_classes):\n",
    "    net = cv2.dnn.readNet(yolo_weights, yolo_config)\n",
    "    classes = []\n",
    "    with open(yolo_classes, \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        height, width, _ = frame.shape\n",
    "        frame_width = width\n",
    "        frame_height = height\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(net.getUnconnectedOutLayersNames())\n",
    "\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5 and class_id == 0:  # Assuming drone class is at index 0\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "        for i in range(len(boxes)):\n",
    "            if i in indexes:\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(classes[class_ids[i]])\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        output_file = os.path.join(output_folder, 'output.avi')\n",
    "        out = cv2.VideoWriter(output_file, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 10, (frame_width, frame_height))\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_directory = \"/Users/muhabelgamal/Documents/NJIT/CS370AI/Drone_Tracking_2.mp4/\"  # Change this to the directory containing your videos\n",
    "    output_directory = \"Detections\"  # Change this to the desired output directory\n",
    "    yolo_weights_file = \"/Users/muhabelgamal/Documents/NJIT/CS370AI/yolov3.weights\"  # Change this to the path of YOLO weights file\n",
    "    yolo_config_file = \"/Users/muhabelgamal/Documents/NJIT/CS370AI/yolov3.cfg\"  # Change this to the path of YOLO configuration file\n",
    "    yolo_classes_file = \"/Users/muhabelgamal/Documents/NJIT/CS370AI/coco.names\"  # Change this to the path of YOLO classes file\n",
    "\n",
    "    videos = [f for f in os.listdir(video_directory) if f.endswith(('.mp4', '.avi'))]\n",
    "\n",
    "    for video in videos:\n",
    "        video_path = os.path.join(video_directory, video)\n",
    "        output_folder = os.path.join(output_directory, video.split('.')[0])\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        detect_drones(video_path, output_folder, yolo_weights_file, yolo_config_file, yolo_classes_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protos\n",
      "  Downloading protos-0.1.0-py3-none-any.whl (1.3 kB)\n",
      "Installing collected packages: protos\n",
      "Successfully installed protos-0.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install protos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid model file yolov3.weights. Please parse in a '.pt' and '.pth' model file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/muhabelgamal/Documents/NJIT/CS370AI/drone.ipynb Cell 9\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/muhabelgamal/Documents/NJIT/CS370AI/drone.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m yolo_detector \u001b[39m=\u001b[39m VideoObjectDetection()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/muhabelgamal/Documents/NJIT/CS370AI/drone.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m yolo_detector\u001b[39m.\u001b[39msetModelTypeAsYOLOv3()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/muhabelgamal/Documents/NJIT/CS370AI/drone.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m yolo_detector\u001b[39m.\u001b[39;49msetModelPath(\u001b[39m\"\u001b[39;49m\u001b[39m/Users/muhabelgamal/Documents/NJIT/CS370AI/yolov3.weights\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/muhabelgamal/Documents/NJIT/CS370AI/drone.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m yolo_detector\u001b[39m.\u001b[39mloadModel()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/muhabelgamal/Documents/NJIT/CS370AI/drone.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Function to detect drones in a frame\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/imageai/Detection/__init__.py:569\u001b[0m, in \u001b[0;36mVideoObjectDetection.setModelPath\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetModelPath\u001b[39m(\u001b[39mself\u001b[39m, model_path: \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 569\u001b[0m     extension_check(model_path)\n\u001b[1;32m    570\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__detector\u001b[39m.\u001b[39msetModelPath(model_path)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/imageai/backend_check/model_extension.py:7\u001b[0m, in \u001b[0;36mextension_check\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou are trying to use a Tensorflow model with ImageAI. ImageAI now uses PyTorch as backed as from version 3.0.2 . If you want to use the Tensorflow models or a customly trained \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m'\u001b[39m\u001b[39m model, install ImageAI 2.1.6 or earlier. To use the latest Pytorch models, see the documentation in https://imageai.readthedocs.io/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39melif\u001b[39;00m file_path\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mand\u001b[39;00m file_path\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid model file \u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(file_path)\u001b[39m}\u001b[39;00m\u001b[39m. Please parse in a \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.pth\u001b[39m\u001b[39m'\u001b[39m\u001b[39m model file.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid model file yolov3.weights. Please parse in a '.pt' and '.pth' model file."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from imageai.Detection import VideoObjectDetection\n",
    "\n",
    "# Load pre-trained YOLO model\n",
    "yolo_detector = VideoObjectDetection()\n",
    "yolo_detector.setModelTypeAsYOLOv3()\n",
    "yolo_detector.setModelPath(\"/Users/muhabelgamal/Documents/NJIT/CS370AI/yolov3.weights\")\n",
    "yolo_detector.loadModel()\n",
    "\n",
    "# Function to detect drones in a frame\n",
    "def detect_drones(frame):\n",
    "    # Perform object detection\n",
    "    detections = yolo_detector.detectObjectsFromImage(input_image=frame, input_type=\"array\")\n",
    "\n",
    "    # Filter detections for drones\n",
    "    drone_detections = [d[\"name\"] for d in detections if d[\"name\"] == \"drone\"]\n",
    "    return drone_detections\n",
    "\n",
    "# Function to process a video and save frames with detections\n",
    "def process_video(video_path):\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Create a directory to store detections\n",
    "    os.makedirs(\"detections\", exist_ok=True)\n",
    "\n",
    "    for i in range(frame_count):\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect drones in the frame\n",
    "        detections = detect_drones(frame)\n",
    "\n",
    "        # If there are detections, save the frame\n",
    "        if len(detections) > 0:\n",
    "            cv2.imwrite(f\"detections/frame_{i}.png\", frame)\n",
    "\n",
    "    video_capture.release()\n",
    "\n",
    "# Process multiple videos in a directory\n",
    "def process_videos_in_directory(directory_path):\n",
    "    video_files = [f for f in os.listdir(directory_path) if f.endswith(\".mp4\")]\n",
    "\n",
    "    for video_file in video_files:\n",
    "        video_path = os.path.join(directory_path, video_file)\n",
    "        process_video(video_path)\n",
    "\n",
    "# Example usage\n",
    "videos_directory = \"/Users/muhabelgamal/Documents/NJIT/CS370AI/Drone_Tracking_1.mp4/Drone Tracking 1.mp4\"\n",
    "process_videos_in_directory(videos_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageai\n",
      "  Downloading imageai-3.0.3-py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imageai\n",
      "Successfully installed imageai-3.0.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imageai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLO model\n",
    "net = cv2.dnn.readNet(\"/Users/muhabelgamal/Documents/NJIT/CS370AI/yolov3.weights\", \"/Users/muhabelgamal/Documents/NJIT/CS370AI/yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"/Users/muhabelgamal/Documents/NJIT/CS370AI/coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "# Function to detect drones in a frame\n",
    "# Function to detect drones in a frame\n",
    "def detect_drones(frame):\n",
    "    height, width, _ = frame.shape\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(layer_names)\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5 and classes[class_id] == \"drone\":\n",
    "                center_x, center_y, w, h = (detection[:4] * np.array([width, height, width, height])).astype('int')\n",
    "                x, y = int(center_x - w / 2), int(center_y - h / 2)\n",
    "                class_ids.append(class_id)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([x, y, w, h])\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    \n",
    "    # Handle the case where indices is a tuple\n",
    "    indices = indices[0] if len(indices) > 0 else []\n",
    "\n",
    "    drone_detections = [boxes[i] for i in indices] if indices else []\n",
    "    return drone_detections\n",
    "\n",
    "\n",
    "# Function to process a video and save frames with detections\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Create a directory to store detections\n",
    "    os.makedirs(\"detections\", exist_ok=True)\n",
    "\n",
    "    for i in range(frame_count):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Detect drones in the frame\n",
    "        detections = detect_drones(frame)\n",
    "\n",
    "        # If there are detections, save the frame\n",
    "        if len(detections) > 0:\n",
    "            cv2.imwrite(f\"detections/frame_{i}.png\", frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Process multiple videos in a directory\n",
    "def process_videos_in_directory(directory_path):\n",
    "    video_files = [f for f in os.listdir(directory_path) if f.endswith(\".mp4\")]\n",
    "\n",
    "    for video_file in video_files:\n",
    "        video_path = os.path.join(directory_path, video_file)\n",
    "        process_video(video_path)\n",
    "\n",
    "# Example usage\n",
    "videos_directory = \"/Users/muhabelgamal/Documents/NJIT/CS370AI/Drone_Tracking_1.mp4\"\n",
    "process_videos_in_directory(videos_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_videos_in_directory(videos_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
